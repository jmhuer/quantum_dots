{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled12.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPbJbhkNPUOR/TknDq90b8p",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmhuer/quantum_dots/blob/main/quantum_dots_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyiZYk_GcXQE"
      },
      "source": [
        "# Load data from excell\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFF6ShtM2arX",
        "outputId": "f8eaafce-ea96-4076-dde7-901dbaa4ec83"
      },
      "source": [
        "!pip install skorch\n",
        "!pip install tqdm\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: skorch in /usr/local/lib/python3.7/dist-packages (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from skorch) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.7/dist-packages (from skorch) (4.41.1)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from skorch) (0.8.9)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from skorch) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from skorch) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->skorch) (1.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHStJWQsbRg1"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "def open_excell(filename):\n",
        "    excell = pd.ExcelFile(filename)\n",
        "    excell.sheet_names\n",
        "    df = excell.parse(\"Sheet1\")\n",
        "    df.columns = df.columns.map(str)\n",
        "    df = df.dropna().reset_index(drop=True)\n",
        "    return df\n",
        "\n",
        "df = open_excell(\"/content/QDots data - Juan.xlsx\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQd7hHq4qytX"
      },
      "source": [
        "## Pre-processing + model defenitions before training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBw-MgBYqyF1"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "X_columns  = [\"415\",\"445\",\"480\", \"515\", \"555\", \"590\", \"630\", \"680\"]\n",
        "Y1_columns = [\"# emitters λ1 (x1010)\"]\n",
        "Y2_columns = [\"# emitters λ2 (x1010)\"]\n",
        "Y_columns  = [\"# emitters λ1 (x1010)\", \"# emitters λ2 (x1010)\"]\n",
        "\n",
        "##LINEAR REGRESSION\n",
        "lr_reg = make_pipeline(LinearRegression())\n",
        "\n",
        "##RandomForestRegressor\n",
        "rf_reg = make_pipeline(StandardScaler(), RandomForestRegressor())\n",
        "parameters = {'randomforestregressor__max_depth':[1,2,3,4,5]}\n",
        "rf_reg = GridSearchCV(rf_reg, parameters)\n",
        "  \n",
        "##SVM\n",
        "svr = make_pipeline(StandardScaler(), SVR(kernel='linear'))\n",
        "parameters = {'svr__kernel':['linear', 'rbf'], 'svr__epsilon':[0.1, 0.2, 0.3,0.6], 'svr__C': [0.1,0.5,1,2,3]}\n",
        "svr = GridSearchCV(svr, parameters)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbVTXkEnydv3"
      },
      "source": [
        "# NN stuff here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CY5agDS6ydI7",
        "outputId": "cbeca126-8899-46be-8419-ce594312da88"
      },
      "source": [
        "from torch import nn\n",
        "from skorch import NeuralNetRegressor\n",
        "\n",
        "class MultivariateLinearRegression(nn.Module):\n",
        "    def __init__(self, input = 8, num_units=10, nonlin=nn.LeakyReLU()):\n",
        "          super(MultivariateLinearRegression, self).__init__()\n",
        "          self.dense0 = nn.Linear(input, num_units)\n",
        "          self.nonlin = nonlin\n",
        "          self.dropout = nn.Dropout(0.1)\n",
        "          self.output = nn.Linear(num_units, 1)\n",
        "    def forward(self, X, **kwargs):\n",
        "          X = self.nonlin(self.dense0(X))\n",
        "          X = self.dropout(X)\n",
        "          X = self.output(X)\n",
        "          return X\n",
        "\n",
        "net = NeuralNetRegressor(\n",
        "    MultivariateLinearRegression().double(),\n",
        "    iterator_train__shuffle = False,\n",
        "    train_split = False,\n",
        "    verbose = 0)\n",
        "\n",
        "myNN_reg = make_pipeline(StandardScaler(), net)\n",
        "\n",
        "params = {\n",
        "    'neuralnetregressor__lr': [0.001, 0.002, 0.003],\n",
        "    'neuralnetregressor__max_epochs': [10, 20, 30]\n",
        "}\n",
        "myNN_reg = GridSearchCV(myNN_reg, params)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0PMkxpX5zOk"
      },
      "source": [
        "##Training loop w/ cross-validation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkC4fqXe5yVG",
        "outputId": "2d35b0c7-2da5-4154-964d-8c884df74c05"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "##For Cross validations \n",
        "kf = KFold(n_splits=10, random_state=42, shuffle=True) # Define the split - into 10 folds \n",
        "k_accuracy = {\"R2_lr\": [],\"MSE_lr\": [], \"R2_rf\": [],\"MSE_rf\": [],\"R2_svr\": [],\"MSE_svr\": [],\"R2_nn\": [],\"MSE_nn\": []}\n",
        "\n",
        "##a progress bar because Im fancy\n",
        "pbar = tqdm(total=100,position=0, leave=True)\n",
        "\n",
        "##MAIN LOOP\n",
        "for train_index, test_index in kf.split(df):\n",
        "    X_train, X_test = df.loc[train_index, X_columns], df.loc[test_index, X_columns]\n",
        "    Y_train, Y_test = df.loc[train_index, Y1_columns], df.loc[test_index, Y1_columns]\n",
        "\n",
        "    ##LINEAR REGRESSION\n",
        "    lr_reg.fit(X_train, Y_train.values.ravel())\n",
        "    Y_pred = lr_reg.predict(X_test)\n",
        "    #store preformance metrics\n",
        "    k_accuracy['MSE_lr'].append(mean_squared_error(Y_test, Y_pred))\n",
        "    k_accuracy['R2_lr'].append(lr_reg.score(X_test, Y_pred))\n",
        "\n",
        "\n",
        "    ##RandomForestRegressor\n",
        "    rf_reg.fit(X_train, Y_train.values.ravel())\n",
        "    Y_pred = rf_reg.predict(X_test)\n",
        "    #store preformance metrics\n",
        "    k_accuracy['R2_rf'].append(mean_squared_error(Y_test, Y_pred))\n",
        "    k_accuracy['MSE_rf'].append(rf_reg.score(X_test, Y_pred))\n",
        "\n",
        "\n",
        "    ##Support Vecotor Regressor \n",
        "    svr.fit(X_train, Y_train.values.ravel())\n",
        "    Y_pred = svr.predict(X_test)\n",
        "    #store preformance metrics\n",
        "    k_accuracy['MSE_svr'].append(mean_squared_error(Y_test, Y_pred))\n",
        "    k_accuracy['R2_svr'].append(svr.score(X_test, Y_pred))\n",
        "\n",
        "\n",
        "    ##NN Regressor\n",
        "    myNN_reg.fit(X_train, Y_train.values)\n",
        "    Y_pred = myNN_reg.predict(X_test)\n",
        "    #store preformance metrics\n",
        "    k_accuracy['MSE_nn'].append(mean_squared_error(Y_test, Y_pred))\n",
        "    k_accuracy['R2_nn'].append(myNN_reg.score(X_test, Y_pred))\n",
        "\n",
        "    pbar.update(10)\n",
        "pbar.close()\n",
        "print('\\n')\n",
        "\n",
        "for i in k_accuracy.keys():\n",
        "    print('\\n', i,\" : \", sum(k_accuracy[i]) / len(k_accuracy[i]))\n",
        "    print(\"---\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:42<00:00,  1.02s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " R2_lr  :  1.0\n",
            "---\n",
            "\n",
            " MSE_lr  :  4.050225300323952\n",
            "---\n",
            "\n",
            " R2_rf  :  0.7954854691876657\n",
            "---\n",
            "\n",
            " MSE_rf  :  1.0\n",
            "---\n",
            "\n",
            " R2_svr  :  1.0\n",
            "---\n",
            "\n",
            " MSE_svr  :  4.476981793012247\n",
            "---\n",
            "\n",
            " R2_nn  :  1.0\n",
            "---\n",
            "\n",
            " MSE_nn  :  13.097932144468876\n",
            "---\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xg_ANKQ0JCa"
      },
      "source": [
        "# Ploting utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GudKpHXc0MBg"
      },
      "source": [
        "import plotly.graph_objects as graph\n",
        "def plot(all_history:list, title:str, log = False):\n",
        "    \"\"\"\n",
        "    input:\n",
        "        all_history: list of dicts to plot\n",
        "    ret:\n",
        "        None: show plotly fig\n",
        "    \"\"\"\n",
        "    fig = graph.Figure(layout = graph.Layout(title=graph.layout.Title(text=title))) \n",
        "    for i in range(len(all_history)):\n",
        "        fig.add_trace(graph.Scatter(x = all_history[i][\"x\"], \n",
        "                                    y = all_history[i][\"y\"],\n",
        "                                    name = all_history[i][\"legend\"])) \n",
        "    if log: fig.update_xaxes(type=\"log\")\n",
        "    fig.show()\n"
      ],
      "execution_count": 8,
      "outputs": []
    }
  ]
}