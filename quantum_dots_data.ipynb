{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled12.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO7jMFDT0XEBLTDASK/BChN",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmhuer/quantum_dots/blob/main/quantum_dots_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyiZYk_GcXQE"
      },
      "source": [
        "# Load data from excell\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFF6ShtM2arX",
        "outputId": "5822ba0e-6d54-4efa-e5c3-85f8c511706e"
      },
      "source": [
        "!pip install skorch\n",
        "!pip install tqdm\n",
        "!git clone https://github.com/jmhuer/optimization_tools\n",
        "\n",
        "from optimization_tools.utils import download_gdrive\n",
        "data = '14mee8d0GDbwNzIprVSJoWdojGtqO_aTX' ##google drive id of excell \n",
        "download_gdrive(data)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: skorch in /usr/local/lib/python3.7/dist-packages (0.10.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from skorch) (1.4.1)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.7/dist-packages (from skorch) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from skorch) (1.19.5)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from skorch) (0.8.9)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from skorch) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->skorch) (1.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n",
            "fatal: destination path 'optimization_tools' already exists and is not an empty directory.\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=14mee8d0GDbwNzIprVSJoWdojGtqO_aTX\n",
            "To: /content/QDots data - Juan.xlsx\n",
            "100%|##########| 39.7k/39.7k [00:00<00:00, 15.0MB/s]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHStJWQsbRg1"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "def open_excel(filename):\n",
        "    excell = pd.ExcelFile(filename)\n",
        "    excell.sheet_names\n",
        "    df = excell.parse(\"Sheet1\")\n",
        "    df.columns = df.columns.map(str)\n",
        "    df = df.dropna().reset_index(drop=True)\n",
        "    return df\n",
        "\n",
        "df = open_excel(\"/content/QDots data - Juan.xlsx\")"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sq5mC4EgpAne",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "6e5b04d8-45e4-4ff2-b1fb-bc719687803f"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Time (min)</th>\n",
              "      <th>μL</th>\n",
              "      <th>nM λ1</th>\n",
              "      <th>nM λ2</th>\n",
              "      <th>λ1 (nm)</th>\n",
              "      <th>λ2 (nm)</th>\n",
              "      <th># emitters λ1 (x1010)</th>\n",
              "      <th># emitters λ2 (x1010)</th>\n",
              "      <th>415</th>\n",
              "      <th>445</th>\n",
              "      <th>480</th>\n",
              "      <th>515</th>\n",
              "      <th>555</th>\n",
              "      <th>590</th>\n",
              "      <th>630</th>\n",
              "      <th>680</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-04-12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>620.0</td>\n",
              "      <td>560.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-04-12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>620.0</td>\n",
              "      <td>560.0</td>\n",
              "      <td>90.3321</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>106.0</td>\n",
              "      <td>666.0</td>\n",
              "      <td>4320.0</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-04-12</td>\n",
              "      <td>1.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>620.0</td>\n",
              "      <td>560.0</td>\n",
              "      <td>90.3321</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>107.0</td>\n",
              "      <td>675.0</td>\n",
              "      <td>4413.0</td>\n",
              "      <td>25.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-04-12</td>\n",
              "      <td>2.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>620.0</td>\n",
              "      <td>560.0</td>\n",
              "      <td>90.3321</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>107.0</td>\n",
              "      <td>677.0</td>\n",
              "      <td>4439.0</td>\n",
              "      <td>25.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-04-12</td>\n",
              "      <td>3.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>620.0</td>\n",
              "      <td>560.0</td>\n",
              "      <td>90.3321</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>106.0</td>\n",
              "      <td>678.0</td>\n",
              "      <td>4457.0</td>\n",
              "      <td>25.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Unnamed: 0  Time (min)    μL  nM λ1  nM λ2  ...   515    555    590     630   680\n",
              "0 2021-04-12         0.0   0.0    0.0    0.0  ...   1.0    0.0    0.0     4.0   0.0\n",
              "1 2021-04-12         0.0  30.0   50.0    0.0  ...  67.0  106.0  666.0  4320.0  24.0\n",
              "2 2021-04-12         1.0  30.0   50.0    0.0  ...  69.0  107.0  675.0  4413.0  25.0\n",
              "3 2021-04-12         2.0  30.0   50.0    0.0  ...  69.0  107.0  677.0  4439.0  25.0\n",
              "4 2021-04-12         3.0  30.0   50.0    0.0  ...  69.0  106.0  678.0  4457.0  25.0\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQd7hHq4qytX"
      },
      "source": [
        "## Pre-processing + model defenitions before training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBw-MgBYqyF1"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "\n",
        "\n",
        "##LINEAR REGRESSION\n",
        "lr_reg = make_pipeline(LinearRegression())\n",
        "\n",
        "##RandomForestRegressor\n",
        "rf_reg = make_pipeline(StandardScaler(), RandomForestRegressor())\n",
        "parameters = {'randomforestregressor__max_depth':[1,2,3,4,5]}\n",
        "rf_reg = GridSearchCV(rf_reg, parameters)\n",
        "  \n",
        "##SVM\n",
        "svr = make_pipeline(StandardScaler(), SVR(kernel='linear'))\n",
        "parameters = {'svr__kernel':['linear', 'rbf'], 'svr__epsilon':[0.1, 0.2, 0.3,0.6], 'svr__C': [0.1,0.5,1,2,3]}\n",
        "svr = GridSearchCV(svr, parameters)\n",
        "\n",
        "##guassian process \n",
        "# Instantiate a Gaussian Process model\n",
        "gp = make_pipeline(StandardScaler(), GaussianProcessRegressor( n_restarts_optimizer=9, normalize_y=True))\n",
        "parameters = {'gaussianprocessregressor__kernel':[RBF(1, (1e-1, 1e1)), RBF(10, (1e-1, 1e2)) ]}\n",
        "gp = GridSearchCV(gp, parameters)\n",
        "\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbVTXkEnydv3"
      },
      "source": [
        "# NN stuff here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CY5agDS6ydI7"
      },
      "source": [
        "from torch import nn\n",
        "from skorch import NeuralNetRegressor\n",
        "\n",
        "class MultivariateLinearRegression(nn.Module):\n",
        "    def __init__(self, input = 8, output=1, num_units=10, nonlin=nn.LeakyReLU()):\n",
        "          super(MultivariateLinearRegression, self).__init__()\n",
        "          self.dense0 = nn.Linear(input, num_units)\n",
        "          self.nonlin = nonlin\n",
        "          self.dropout = nn.Dropout(0.1)\n",
        "          self.output = nn.Linear(num_units, output)\n",
        "    def forward(self, X):\n",
        "          X = self.nonlin(self.dense0(X))\n",
        "          X = self.dropout(X)\n",
        "          X = self.output(X)\n",
        "          return X\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## single variable \n",
        "net = NeuralNetRegressor(\n",
        "    MultivariateLinearRegression().double(),\n",
        "    iterator_train__shuffle = False,\n",
        "    train_split = False,\n",
        "    verbose = 0)\n",
        "\n",
        "myNN_reg = make_pipeline(StandardScaler(), net)\n",
        "\n",
        "params = {\n",
        "    'neuralnetregressor__lr': [0.001, 0.002, 0.003],\n",
        "    'neuralnetregressor__max_epochs': [10, 20, 30]\n",
        "}\n",
        "myNN_reg = GridSearchCV(myNN_reg, params)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## multivariate variable \n",
        "net2 = NeuralNetRegressor(\n",
        "    MultivariateLinearRegression(output=2).double(),\n",
        "    iterator_train__shuffle = False,\n",
        "    train_split = False,\n",
        "    verbose = 0)\n",
        "\n",
        "myNN_reg2 = make_pipeline(StandardScaler(), net2)\n",
        "\n",
        "params = {\n",
        "    'neuralnetregressor__lr': [0.001, 0.002, 0.003],\n",
        "    'neuralnetregressor__max_epochs': [10, 20, 30]\n",
        "}\n",
        "myNN_reg2 = GridSearchCV(myNN_reg2, params)\n"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZT2JZe0Kg8Z"
      },
      "source": [
        "# overfit criteria "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Q2dD_a2Kgfy"
      },
      "source": [
        "# calculate aic for regression\n",
        "def calculate_aic(n, mse, num_params):\n",
        "\taic = n * log(mse) + 2 * num_params\n",
        "\treturn aic\n",
        "\n",
        "\n",
        "# calculate bic for regression\n",
        "def calculate_bic(n, mse, num_params):\n",
        "\tbic = n * log(mse) + num_params * log(n)\n",
        "\treturn bic"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0PMkxpX5zOk"
      },
      "source": [
        "##Training loop w/ cross-validation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkC4fqXe5yVG",
        "outputId": "96f2925f-99d2-4702-bc89-3e6f791326bb"
      },
      "source": [
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "##function to help store history and metrics of each cross validation run\n",
        "history = dict()\n",
        "def append_history(history, algorithm, name, X_test, Y_test):\n",
        "    #calculate performance metrics\n",
        "    Y_pred = algorithm.predict(X_test)\n",
        "    score = algorithm.score(X_test, Y_test)\n",
        "    #if dict does not contain current alg, create a key\n",
        "    if name not in history.keys(): \n",
        "        history[name] = {\"mse\": [], \"r2\": [], \"predictions\": [], \"actual\": []}\n",
        "    #store preformance metrics & history\n",
        "    mse = mean_squared_error(Y_test, Y_pred)\n",
        "    history[name][\"mse\"].append(mse)\n",
        "    history[name][\"r2\"].append(score)\n",
        "    history[name][\"predictions\"].append(Y_pred)\n",
        "    history[name][\"actual\"].append(Y_test)\n",
        "    return history\n",
        "\n",
        "\n",
        "\n",
        "X_columns  = [\"415\",\"445\",\"480\", \"515\", \"555\", \"590\", \"630\", \"680\"]\n",
        "Y1_columns = [\"# emitters λ1 (x1010)\"]\n",
        "Y2_columns = [\"# emitters λ2 (x1010)\"]\n",
        "Y_columns  = [\"# emitters λ1 (x1010)\", \"# emitters λ2 (x1010)\"]\n",
        "\n",
        "\n",
        "##For Cross validations \n",
        "n_splits = 10\n",
        "kf = KFold(n_splits=n_splits, random_state=42, shuffle=True) # Define the split - into 10 folds \n",
        "\n",
        "##A progress bar because Im fancy\n",
        "pbar = tqdm(total=100,position=0, leave=True)\n",
        "\n",
        "##MAIN LOOP\n",
        "for train_index, test_index in kf.split(df):\n",
        "    X_train, X_test = df.loc[train_index, X_columns], df.loc[test_index, X_columns]\n",
        "    Y_train, Y_test = df.loc[train_index, Y2_columns], df.loc[test_index, Y2_columns]\n",
        "    Y_train_both, Y_test_both = df.loc[train_index, Y_columns], df.loc[test_index, Y_columns]\n",
        "\n",
        "    ### Gaussian process regression \n",
        "    # Fit to data using Maximum Likelihood Estimation of the parameters\n",
        "    gp.fit(X_train, Y_train.values)\n",
        "    history = append_history(history, gp, \"GP_reg\", X_test, Y_test)\n",
        "\n",
        "    ##NN Regressor multivariate\n",
        "    myNN_reg2.fit(X_train, Y_train_both.values)\n",
        "    history = append_history(history, myNN_reg2, \"myNN_reg2\", X_test, Y_test_both)\n",
        "    \n",
        "    ##LINEAR REGRESSION\n",
        "    lr_reg.fit(X_train, Y_train.values.ravel())\n",
        "    history = append_history(history, lr_reg, \"linear_regression\", X_test, Y_test)\n",
        "\n",
        "    ##RandomForestRegressor\n",
        "    rf_reg.fit(X_train, Y_train.values.ravel())\n",
        "    history = append_history(history, rf_reg, \"rf_reg\", X_test, Y_test)\n",
        "\n",
        "    ##Support Vecotor Regressor \n",
        "    svr.fit(X_train, Y_train.values.ravel())\n",
        "    history = append_history(history, svr, \"svr\", X_test, Y_test)\n",
        "\n",
        "    # ##NN Regressor\n",
        "    myNN_reg.fit(X_train, Y_train.values)\n",
        "    history = append_history(history, myNN_reg, \"myNN_reg\", X_test, Y_test)\n",
        "\n",
        "\n",
        "\n",
        "    pbar.update(10)\n",
        "pbar.close()\n",
        "\n",
        "print('\\n')\n",
        "for i in history.keys():\n",
        "    print('\\n', i,\" : \", sum(history[i][\"mse\"]) / len(history[i][\"mse\"]))\n",
        "    print(\"---\")\n",
        "\n",
        "\n",
        "# num_params = len(lr_reg.best_estimator_[1].coef_) + 1\n",
        "# print(calculate_bic(len(Y_test), history[\"linear_regression\"][\"mse\"], num_params))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zls19buetx8t"
      },
      "source": [
        "print('\\n')\n",
        "for i in history.keys():\n",
        "    print('\\n', i,\" : \", sum(history[i][\"r2\"]) / len(history[i][\"r2\"]))\n",
        "    print(\"---\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xg_ANKQ0JCa"
      },
      "source": [
        "# Ploting utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GudKpHXc0MBg"
      },
      "source": [
        "import plotly.graph_objects as graph\n",
        "def plot(all_history:list, title:str, log = False):\n",
        "    \"\"\"\n",
        "    input:\n",
        "        all_history: list of dicts to plot\n",
        "    ret:\n",
        "        None: show plotly fig\n",
        "    \"\"\"\n",
        "    symbol_sequence= ['circle-open', 'circle', 'circle-open-dot', 'square']\n",
        "    fig = graph.Figure(layout = graph.Layout(title=graph.layout.Title(text=title))) \n",
        "    for i in range(len(all_history)):\n",
        "        fig.add_trace(graph.Scatter(x = all_history[i][\"x\"], \n",
        "                                    y = all_history[i][\"y\"],\n",
        "                                    name = all_history[i][\"legend\"],\n",
        "                                    mode='markers',\n",
        "                                    marker_size=5,\n",
        "                                    marker_symbol=all_history[i][\"marker_symbol\"])) \n",
        "    if log: fig.update_xaxes(type=\"log\")\n",
        "    fig.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRwyDtwtGKiJ"
      },
      "source": [
        "# Plot each CV split validation on same plot predicted vs actual"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSJR4Z6x54T2"
      },
      "source": [
        "import numpy as np\n",
        "names = list(history.keys())\n",
        "\n",
        "n_splits = 10\n",
        "\n",
        "#perfect plot\n",
        "perfect_plot = {\"legend\": \"actuals\", \n",
        "                \"x\": list(np.linspace(0, 100, num=1000, endpoint=True)), \n",
        "                \"y\": list(np.linspace(0, 100, num=1000, endpoint=True)),\n",
        "                \"marker_symbol\": 'line-ne-open'}\n",
        "X,Y = [], []           \n",
        "for alg in names:\n",
        "  for i in range(n_splits):\n",
        "      X = X + list(history[alg][\"actual\"][i].values.ravel())\n",
        "      Y = Y + list(history[alg][\"predictions\"][i].ravel())\n",
        "\n",
        "  current_plot = {\"legend\": \"predictions\", \n",
        "                  \"x\": X, \n",
        "                  \"y\": Y,\n",
        "                  \"marker_symbol\": 'star'}\n",
        "\n",
        "  plot([current_plot, perfect_plot], alg + \" predicted v actual\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "se1JATnV6LVS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}